<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>チャットチャンネル</title>
    <style>
        li{
            list-style: none;
            margin: 10px 0;
        }
        #main-container {
          display: flex;
        }
        .display-container {
          height: 500px;
          width: 50%;
        }
        .display-canvas {
          margin: 10px;
          width: 100%
        }
        #video {
        
        }
    </style>
</head>
<body>

  <script src="https://code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
  <script type="module" src="/static/SpeakerTag.js"></script>
  <script type="module" src="/static/VTuberFrame.js"></script>
  <script src="/static/facetrack/model_pca_20_svm.js"></script>
  <script src="/static/facetrack/clmtrackr.min.js"></script>
  <script src="/static/facetrack/pixi.min.js"></script>
  <div id="main-container">
    <div id="mydisplay-container" class="display-container">
      <video id="video"></video>
      <speaker-tag></speaker-tag>
      <vtuber-frame></vtuber-frame>
    </div>
    <div id="opdisplay-container" class="display-container">
    </div>
  </div>

  <script>
    var width = 600;
    var height = 400;

    var drawRequest = null;
    var stage = new PIXI.Stage(0x000000);
    var renderer = PIXI.autoDetectRenderer(width, height);

    document.getElementById("mydisplay-container").appendChild(renderer.view);

    var texture = PIXI.Texture.fromImage('static/img/snow.png');
    var face_texture = PIXI.Texture.fromImage('static/img/kao.png');

    var facepoints = [];
    var FACE_POINTS = 71;
    var right = 1,
        left = 13,
        chin = 7,
        brow = 33,
        nouse = 62
    var FEATURE_POINTS = [right, left, chin, brow, nouse];

    for (var i = 0; i < FEATURE_POINTS.length; i++) {
      var point = new PIXI.Sprite(texture);
      point.scale.x = 0.1;
      point.scale.y = 0.1;
      facepoints.push(point);
      stage.addChild(point);
    } 
    var face_sprite = new PIXI.Sprite(face_texture);
    face_sprite.height = 1000;
    face_sprite.width = 1000;
    console.log(face_sprite)
    stage.addChild(face_sprite);

    var ctrack = new clm.tracker({searchWindow : 30});
    var canvas1 = renderer.view;
    console.log(renderer.view);
    var disp = document.getElementById("mydisplay-container");

    /*
    distance = (x, y) => {
      return Math.pow(Math.pow(x[0]-y[0], 2) + Math.pow(x[1]-y[1], 2), 0.5)
    }

    rotate = (l, r, b, c) => {
      // l -> left, r -> right, b -> brow, c -> chin
      return -Math.atan2(r[1]-l[1], -r[0]+l[0]);
    }
    
    function loop() {
      var currentpoints = ctrack.getCurrentPosition()
      if (currentpoints) {
        face_sprite.position.x = 0;
        face_sprite.position.y = 0;

        for (var i = 0; i < FEATURE_POINTS.length; i++) {
          var point = currentpoints[FEATURE_POINTS[i]];
          facepoints[i].position.x = point[0];
          facepoints[i].position.y = point[1];
          face_sprite.position.x += point[0]/FEATURE_POINTS.length;
          face_sprite.position.y += point[1]/FEATURE_POINTS.length;
        }
        var fw = distance(currentpoints[left], currentpoints[right]), fh = distance(currentpoints[chin], currentpoints[nouse])*2;
        var r = rotate(currentpoints[left], currentpoints[right], currentpoints[brow], currentpoints[chin])
        face_sprite.width = fw;
        face_sprite.height = fh;
        face_sprite.anchor.x = 0.5;
        face_sprite.anchor.y = 0.5;
        face_sprite.rotation = r;
        renderer.render(stage);
      }
      drawRequest = requestAnimationFrame(loop);
    }

    navigator.mediaDevices.getUserMedia({
        video: true,
        audio: false
    }).then((mediaStream) => {
      video.srcObject = mediaStream;
      video.play();
      video.onloadedmetadata = () => {
        loop();
        video.width = canvas1.width;
        video.height = canvas1.height;
        ctrack.init(pModel);
        ctrack.start(video);
      }
    });

    function clmtrackrConvergedHandler() {
      console.log("顔検出成功")

      document.removeEventListener("clmtrackrLost", clmtrackrLostHandler);
      document.removeEventListener("clmtrackrConverged", clmtrackrConvergedHandler);
    }

    function clmtrackrLostHandler () {
      //cancelAnimationFrame(drawRequest);
      // ctrack.stop();
      document.removeEventListener("clmtrackrLost", clmtrackrLostHandler);
      document.removeEventListener("clmtrackrConverged", clmtrackrConvergedHandler);
      console.log("顔検出失敗")
    }
    */
  </script>
</body>
</html>


